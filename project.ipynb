{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### load 'A_Z Handwritten Data.csv' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('A_Z Handwritten Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get copy from the original to preprocess\n",
    "\n",
    "df_pre = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about the dataset\n",
    "\n",
    "display(df_pre.describe())\n",
    "\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "\n",
    "# to know the number of the rows\n",
    "print(f\"total records:\",len(df), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Identify the number of unique classes and show their distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that the fisrt column is the target \n",
    "# contains numbers from 0 to 25 (A-Z).\n",
    "\n",
    "# Count the frequency of each letter\n",
    "# df_pre[\"0\"] to get the first column as its name is \"0\" from the above information\n",
    "unique_classes, counts = np.unique(df_pre[\"0\"], return_counts=True)\n",
    "\n",
    "print(\"Unique classes and their counts:\")\n",
    "for cls, count in zip(unique_classes, counts):\n",
    "    print(f\"{chr(cls + ord('A'))}: {count}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# show the distribution\n",
    "plt.bar(unique_classes, counts)\n",
    "plt.title(\"Distribution of Classes\")\n",
    "plt.xlabel(\"Class Labels (A-Z)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Normalize each image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "# divide by 255 to make the data between 0 and 1\n",
    "df_normalized = df_pre.astype(\"float32\") / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Reshape the flattened vectors to reconstruct and display the corresponding images while testing the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the target column (first column)\n",
    "# we get it from the original dataset not from the normalized dataset \n",
    "# iloc[Rows , Columns] , \":\" means all records , \"0\" mean the first column \n",
    "df_targets = df_pre.iloc[:, 0].values  \n",
    "\n",
    "# Extract the image data (columns 2 to 785) and reshape each row into 28x28\n",
    "# iloc[Rows , Columns] , \":\" means all records , \"1:\" mean the second column to the last column \n",
    "# the data already is 2d array so the \"images\" will be 3d array \n",
    "# as in each index will contain 2d array ( 28 X 28 ) \n",
    "# \"-1\" automatically calculates the number of images based on the total data size. \n",
    "# mean will return the number of rows\n",
    "df_images = df_normalized.iloc[:, 1:].values.reshape(-1, 28, 28)  \n",
    "\n",
    "\n",
    "print(\"Images shape:\", df_images.shape)\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# the firts image in 2d array   \n",
    "print(df_images[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Letters Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have the unique classes and its counts \n",
    "# we need cumulative sum to get index that represents each letter\n",
    "# Create list from the cumulative sum as the following\n",
    "# sum(count[:i]) means sum the counts from the first index to the i index\n",
    "cumulative_counts = [sum(counts[:i]) for i in range(len(counts) + 1)]  \n",
    "\n",
    "\n",
    "# Create a figure for displaying all letters\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Loop through all 26 letters\n",
    "for i, letter in enumerate(unique_classes):\n",
    "    # Get the starting index for the current letter\n",
    "    idx = cumulative_counts[i]\n",
    "\n",
    "    # Create a grid of 4 rows and 7 columns for visualization \n",
    "    plt.subplot(4, 7, i + 1)  \n",
    "    \n",
    "    # Display the image using \"imshow\" that used to display data as an image on a 2D\n",
    "    plt.imshow(df_images[idx], cmap='gray')  \n",
    "\n",
    "    # Show the letter as character not as number\n",
    "    # \"ord\" get the ASCII representation then add the letter number \n",
    "    # then convert to character using casting \"chr\"\n",
    "    plt.title(f\"Letter: {chr(letter + ord('A'))}\") \n",
    "\n",
    "    # Hide axes \n",
    "    plt.axis(\"off\")  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Split the data into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make the 80% from the data training set and 20% from the data testing set\n",
    "# random state to ensure that the split return the same data each run\n",
    "\n",
    "\n",
    "# The final data will be worked on\n",
    "df_images_train, df_images_test, df_targets_train, df_targets_test = train_test_split(df_images, df_targets, test_size=0.2, random_state=42) \n",
    "\n",
    "\n",
    "\n",
    "# Ensure that the training set and testing set contains all the unique classes\n",
    "\n",
    "targets_train_unique_classes = np.unique(df_targets_train)\n",
    "\n",
    "print(\"No. Of Unique classes in targets train : \\n\" ,len(targets_train_unique_classes) )\n",
    "print(\"-\"*80)\n",
    "\n",
    "targets_test_unique_classes = np.unique(df_targets_test)\n",
    "\n",
    "print(\"No. Of Unique classes in targets test : \\n\" ,len(targets_test_unique_classes) )\n",
    "print(\"-\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_images_train, df_targets_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ theta)\n",
    "    return (-1/m) * (y.T @ np.log(h) + (1 - y).T @ np.log(1 - h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ascent(X, y, theta, learning_rate, iterations, X_val=None, y_val=None):\n",
    "    m = len(y)\n",
    "    costs = []\n",
    "    val_costs = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        h = sigmoid(X @ theta)\n",
    "        gradient = (1 / m) * (X.T @ (y - h))  \n",
    "        theta += learning_rate * gradient\n",
    "        cost = cost_function(X, y, theta)\n",
    "        costs.append(cost)\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            # Calculate training accuracy\n",
    "            train_pred = (h >= 0.5).astype(int)\n",
    "            train_accuracy = np.mean(train_pred == y)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Track validation cost (if provided)\n",
    "        if X_val is not None and y_val is not None:\n",
    "            val_cost = cost_function(X_val, y_val, theta)\n",
    "            val_costs.append(val_cost)\n",
    "            if i % 20 == 0:\n",
    "                val_h = sigmoid(X_val @ theta)\n",
    "                val_pred = (val_h >= 0.5).astype(int)\n",
    "                val_accuracy = np.mean(val_pred == y_val)\n",
    "                val_accuracies.append(val_accuracy)\n",
    "\n",
    "    return theta, costs, val_costs, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_all(X, y, num_classes, learning_rate=0.01, iterations=1000, X_val=None, y_val=None):\n",
    "    m, n = X.shape\n",
    "    all_theta = np.zeros((num_classes, n))\n",
    "    all_costs = []\n",
    "    all_val_costs = []\n",
    "    all_train_accuracies = []\n",
    "    all_val_accuracies = []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        print(f\"Training classifier for class {c}...\")\n",
    "        theta = np.zeros(n)\n",
    "        y_binary = (y == c).astype(int)\n",
    "        theta, costs, val_costs, train_accuracies, val_accuracies = gradient_ascent(X, y_binary, theta, learning_rate, iterations, X_val, y_val)\n",
    "        all_theta[c] = theta\n",
    "        all_costs.append(costs)\n",
    "        all_val_costs.append(val_costs)\n",
    "        all_train_accuracies.append(train_accuracies)\n",
    "        all_val_accuracies.append(val_accuracies)\n",
    "\n",
    "    return all_theta, all_costs, all_val_costs, all_train_accuracies, all_val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, all_theta):\n",
    "    probabilities = sigmoid(X @ all_theta.T)\n",
    "    return np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images for logistic regression and add intercept term\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test = df_images_test.reshape(df_images_test.shape[0], -1)\n",
    "\n",
    "# Add intercept term (bias)\n",
    "X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "X_test = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "X_val = np.c_[np.ones(X_val.shape[0]), X_val]\n",
    "\n",
    "# Train the model\n",
    "num_classes = len(unique_classes)\n",
    "learning_rate = 0.1\n",
    "iterations = 1000\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "\n",
    "all_theta, all_costs, val_costs, all_train_accuracies, all_val_accuracies = one_vs_all(X_train, y_train, num_classes, learning_rate, iterations, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot figures for the cost function and validation cost\n",
    "plt.figure(figsize=(10, 6))\n",
    "for c in range(num_classes):\n",
    "    plt.plot(all_costs[c], label=f\"Class {c}\")\n",
    "plt.title(\"Cost Function\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for c in range(num_classes):\n",
    "    plt.plot(val_costs[c], label=f\"Class {c}\")\n",
    "plt.title(\"Validation Cost\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for c in range(num_classes):\n",
    "    plt.plot(all_train_accuracies[c], label=f\"Class {c}\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for c in range(num_classes):\n",
    "    plt.plot(all_val_accuracies[c], label=f\"Class {c}\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and testing data\n",
    "y_pred_train = predict(X_train, all_theta)\n",
    "y_pred_val = predict(X_val, all_theta)\n",
    "y_pred_test = predict(X_test, all_theta)\n",
    "print(len(all_theta))\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "\n",
    "test_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion matrix and F1 scores\n",
    "conf_matrix = confusion_matrix(df_targets_test, y_pred_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "f1 = f1_score(df_targets_test, y_pred_test, average='weighted')\n",
    "print(f\"Average F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Visualize confusion matrix\n",
    "# class_labels to represent the letters from A to Z\n",
    "import seaborn as sns\n",
    "class_labels = [chr(i + ord('A')) for i in range(26)]\n",
    "\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,         \n",
    "            fmt='g',           \n",
    "            cmap='Blues',       \n",
    "            xticklabels=class_labels,  \n",
    "            yticklabels=class_labels)  \n",
    "\n",
    "plt.ylabel('Actual', fontsize=13)\n",
    "plt.title('Confusion Matrix', fontsize=17, pad=20)\n",
    "plt.gca().xaxis.set_label_position('top')  \n",
    "plt.xlabel('Prediction', fontsize=13)\n",
    "plt.gca().xaxis.tick_top()                \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
